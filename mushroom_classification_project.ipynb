{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom Classification Project ðŸ„\n",
    "\n",
    "## Akbank Makine Ã–ÄŸrenmesi Bootcamp - GÃ¶zetimli Ã–ÄŸrenme Projesi\n",
    "\n",
    "Bu projede, Kaggle'dan alÄ±nan \"Mushroom Classification\" veri setini kullanarak mantarlarÄ±n yenilebilir (edible) veya zehirli (poisonous) olup olmadÄ±ÄŸÄ±nÄ± tahmin eden bir makine Ã¶ÄŸrenmesi modeli geliÅŸtireceÄŸiz.\n",
    "\n",
    "### Proje Hedefleri:\n",
    "- KapsamlÄ± KeÅŸifsel Veri Analizi (EDA) gerÃ§ekleÅŸtirmek\n",
    "- Veri Ã¶n iÅŸleme tekniklerini uygulamak\n",
    "- Ã‡oklu algoritma karÅŸÄ±laÅŸtÄ±rmasÄ± yapmak\n",
    "- En iyi performans gÃ¶steren modeli belirlemek\n",
    "\n",
    "### KullanÄ±lacak Algoritmalar:\n",
    "- Logistic Regression\n",
    "- Ridge Classifier\n",
    "- Decision Tree\n",
    "- Gaussian Naive Bayes\n",
    "- Neural Networks (MLP)\n",
    "- Random Forest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KÃ¼tÃ¼phanelerin Ä°Ã§e AktarÄ±lmasÄ±\n",
    "\n",
    "Projemizde kullanacaÄŸÄ±mÄ±z tÃ¼m kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas and Matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Label Encoder and train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression, Ridge Classifier, Decision Tree\n",
    "# Gaussian Naive Bayes, MLP Classifier and Random Forest models\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Classification Report function\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Seti ve Ã–n Ä°ÅŸleme\n",
    "\n",
    "Veri setimiz 8124 mantar Ã¶rneÄŸi iÃ§ermektedir. Her mantar Ã¶rneÄŸi 22 Ã¶zelliÄŸe sahiptir ve yenilebilir veya zehirli olarak kategorize edilmiÅŸtir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Veriyi Okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the \"mushroom.csv\" file\n",
    "data = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "print(f\"Veri seti boyutu: {data.shape}\")\n",
    "print(f\"Toplam veri noktasÄ±: {len(data)}\")\n",
    "print(f\"Ã–zellik sayÄ±sÄ±: {data.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Veriyi GÃ¶rselleÅŸtirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the head() function to display the first 5 rows of the data\n",
    "print(\"Ä°lk 5 satÄ±r:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri seti hakkÄ±nda genel bilgiler\n",
    "print(\"Veri seti bilgileri:\")\n",
    "print(data.info())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Ä°statistiksel Ã¶zet:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik deÄŸerleri kontrol etme\n",
    "print(\"Eksik deÄŸerler:\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# '?' karakterini eksik deÄŸer olarak kontrol etme\n",
    "print(\"\\n'?' karakteri iÃ§eren sÃ¼tunlar:\")\n",
    "for col in data.columns:\n",
    "    question_marks = (data[col] == '?').sum()\n",
    "    if question_marks > 0:\n",
    "        print(f\"{col}: {question_marks} adet '?' deÄŸeri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KeÅŸifsel Veri Analizi (EDA)\n",
    "\n",
    "Veri setimizi daha iyi anlamak iÃ§in kapsamlÄ± bir analiz gerÃ§ekleÅŸtireceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts method on \"class\" column of data object\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(\"SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
    "print(class_counts)\n",
    "print(f\"\\nYÃ¼zdelik daÄŸÄ±lÄ±m:\")\n",
    "print(data['class'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the bar for edible class\n",
    "# Add the bar for poisonous class\n",
    "# Print the plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts.plot(kind='bar', color=['#2E8B57', '#DC143C'])\n",
    "plt.title('Mantar SÄ±nÄ±flarÄ±nÄ±n DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('SÄ±nÄ±f (e: Yenilebilir, p: Zehirli)', fontsize=12)\n",
    "plt.ylabel('SayÄ±', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_counts.values, labels=['Yenilebilir', 'Zehirli'], \n",
    "        colors=['#2E8B57', '#DC143C'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (YÃ¼zde)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorik deÄŸiÅŸkenlerin benzersiz deÄŸer sayÄ±larÄ±\n",
    "print(\"Her sÃ¼tundaki benzersiz deÄŸer sayÄ±larÄ±:\")\n",
    "for col in data.columns:\n",
    "    unique_count = data[col].nunique()\n",
    "    print(f\"{col}: {unique_count} benzersiz deÄŸer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Ã¶nemli Ã¶zelliklerin gÃ¶rselleÅŸtirilmesi\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Ã–nemli Ã–zelliklerin SÄ±nÄ±flara GÃ¶re DaÄŸÄ±lÄ±mÄ±', fontsize=16, fontweight='bold')\n",
    "\n",
    "important_features = ['odor', 'gill-size', 'gill-color', 'stalk-shape', 'cap-color', 'bruises']\n",
    "\n",
    "for i, feature in enumerate(important_features):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    cross_tab = pd.crosstab(data[feature], data['class'])\n",
    "    cross_tab.plot(kind='bar', ax=axes[row, col], color=['#2E8B57', '#DC143C'])\n",
    "    axes[row, col].set_title(f'{feature.title()} vs SÄ±nÄ±f', fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature.title())\n",
    "    axes[row, col].set_ylabel('SayÄ±')\n",
    "    axes[row, col].legend(['Yenilebilir', 'Zehirli'])\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Veri Ã–n Ä°ÅŸleme\n",
    "\n",
    "Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n kategorik verileri iÅŸleyebilmesi iÃ§in Label Encoding uygulayacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X variable for features\n",
    "X = data.drop('class', axis=1)\n",
    "\n",
    "# Create the y variable for output labels\n",
    "y = data['class']\n",
    "\n",
    "print(f\"Ã–zellik matrisi boyutu: {X.shape}\")\n",
    "print(f\"Hedef deÄŸiÅŸken boyutu: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the features to integers inside a for loop\n",
    "for column in X.columns:\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "# Encode the output labels to integers\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Label Encoding tamamlandÄ±!\")\n",
    "print(f\"Hedef deÄŸiÅŸken: 0 = Yenilebilir, 1 = Zehirli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print X\n",
    "print(\"KodlanmÄ±ÅŸ Ã¶zellik matrisi (ilk 5 satÄ±r):\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print y\n",
    "print(\"KodlanmÄ±ÅŸ hedef deÄŸiÅŸken (ilk 10 deÄŸer):\")\n",
    "print(y[:10])\n",
    "print(f\"\\nHedef deÄŸiÅŸken daÄŸÄ±lÄ±mÄ±:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for i, (val, count) in enumerate(zip(unique, counts)):\n",
    "    label = \"Yenilebilir\" if val == 0 else \"Zehirli\"\n",
    "    print(f\"{val} ({label}): {count} Ã¶rnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Veri Setini BÃ¶lme\n",
    "\n",
    "Veri setimizi %70 eÄŸitim, %30 test olacak ÅŸekilde bÃ¶leceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets with 70-30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"EÄŸitim seti boyutu: {X_train.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test.shape}\")\n",
    "print(f\"EÄŸitim seti hedef daÄŸÄ±lÄ±mÄ±: {np.bincount(y_train)}\")\n",
    "print(f\"Test seti hedef daÄŸÄ±lÄ±mÄ±: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model OluÅŸturma\n",
    "\n",
    "FarklÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± kullanarak modeller oluÅŸturacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object using the LogisticRegression() class\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Create an object using the RidgeClassifier() class\n",
    "ridge_model = RidgeClassifier(random_state=42)\n",
    "\n",
    "# Create an object using the DecisionTreeClassifier() class\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create an object using the GaussianNB() class\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Create an object using the MLPClassifier() class\n",
    "neural_network_model = MLPClassifier(random_state=42, max_iter=1000)\n",
    "\n",
    "print(\"TÃ¼m modeller oluÅŸturuldu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model EÄŸitimi\n",
    "\n",
    "OluÅŸturduÄŸumuz modelleri eÄŸitim verisi ile eÄŸiteceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Classifier model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression modeli eÄŸitildi âœ“\")\n",
    "\n",
    "# Train the Ridge Classifier model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "print(\"Ridge Classifier modeli eÄŸitildi âœ“\")\n",
    "\n",
    "# Train the Decision Tree model\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "print(\"Decision Tree modeli eÄŸitildi âœ“\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "print(\"Naive Bayes modeli eÄŸitildi âœ“\")\n",
    "\n",
    "# Train the Neural Network model\n",
    "neural_network_model.fit(X_train, y_train)\n",
    "print(\"Neural Network modeli eÄŸitildi âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tahmin Yapma\n",
    "\n",
    "EÄŸitilmiÅŸ modellerimizi kullanarak test verisi Ã¼zerinde tahminler yapacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction using the test dataset on Logistic Classifier model\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Make prediction using the test dataset on Ridge Classifier model\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Make prediction using the test dataset on Decision Tree model\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Make prediction using the test dataset on Naive Bayes model\n",
    "naive_bayes_predictions = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Make prediction using the test dataset on Neural Network model\n",
    "neural_network_predictions = neural_network_model.predict(X_test)\n",
    "\n",
    "print(\"TÃ¼m modeller iÃ§in tahminler tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SÄ±nÄ±flandÄ±rma RaporlarÄ± OluÅŸturma\n",
    "\n",
    "Her model iÃ§in detaylÄ± performans raporlarÄ± oluÅŸturacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Classification Report for Logistic Classifier model\n",
    "logistic_report = classification_report(y_test, logistic_predictions, \n",
    "                                       target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "# Create a Classification Report for Ridge Classifier model\n",
    "ridge_report = classification_report(y_test, ridge_predictions, \n",
    "                                   target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "# Create a Classification Report for Decision Tree model\n",
    "decision_tree_report = classification_report(y_test, decision_tree_predictions, \n",
    "                                            target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "# Create a Classification Report for Naive Bayes model\n",
    "naive_bayes_report = classification_report(y_test, naive_bayes_predictions, \n",
    "                                         target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "# Create a Classification Report for Neural Network model\n",
    "neural_network_report = classification_report(y_test, neural_network_predictions, \n",
    "                                             target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "print(\"TÃ¼m sÄ±nÄ±flandÄ±rma raporlarÄ± oluÅŸturuldu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model PerformanslarÄ±nÄ±n GÃ¶rÃ¼ntÃ¼lenmesi\n",
    "\n",
    "Her modelin performansÄ±nÄ± detaylÄ± olarak inceleyeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the report of the Logistic Regression model\n",
    "print(\"=\" * 60)\n",
    "print(\"LOGISTIC REGRESSION MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(logistic_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, logistic_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the report of the Ridge Regression model\n",
    "print(\"=\" * 60)\n",
    "print(\"RIDGE CLASSIFIER MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(ridge_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, ridge_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the report of the Decision Tree model\n",
    "print(\"=\" * 60)\n",
    "print(\"DECISION TREE MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(decision_tree_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, decision_tree_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the report of the Naive Bayes model\n",
    "print(\"=\" * 60)\n",
    "print(\"NAIVE BAYES MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(naive_bayes_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, naive_bayes_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the report of the Neural Network model\n",
    "print(\"=\" * 60)\n",
    "print(\"NEURAL NETWORK MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(neural_network_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, neural_network_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Random Forest Modeli\n",
    "\n",
    "Ek olarak Random Forest algoritmasÄ±nÄ± da test edeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest Classifier object, train it and make predictions\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "random_forest_predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest modeli eÄŸitildi ve tahminler yapÄ±ldÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification Report for Random Forest model\n",
    "random_forest_report = classification_report(y_test, random_forest_predictions, \n",
    "                                            target_names=['Yenilebilir', 'Zehirli'])\n",
    "\n",
    "# Print the classification report\n",
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST MODEL PERFORMANSI\")\n",
    "print(\"=\" * 60)\n",
    "print(random_forest_report)\n",
    "print(f\"DoÄŸruluk OranÄ±: {accuracy_score(y_test, random_forest_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model KarÅŸÄ±laÅŸtÄ±rmasÄ± ve SonuÃ§lar\n",
    "\n",
    "TÃ¼m modellerin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rarak en iyi modeli belirleyeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma\n",
    "models = {\n",
    "    'Logistic Regression': logistic_predictions,\n",
    "    'Ridge Classifier': ridge_predictions,\n",
    "    'Decision Tree': decision_tree_predictions,\n",
    "    'Naive Bayes': naive_bayes_predictions,\n",
    "    'Neural Network': neural_network_predictions,\n",
    "    'Random Forest': random_forest_predictions\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, predictions in models.items():\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TÃœM MODELLERÄ°N PERFORMANS KARÅžILAÅžTIRMASI\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans gÃ¶rselleÅŸtirmesi\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    bars = ax.bar(results_df['Model'], results_df[metric], color=colors[i], alpha=0.7)\n",
    "    ax.set_title(f'{metric} KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine yazma\n",
    "    for bar, value in zip(bars, results_df[metric]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli belirleme\n",
    "best_model = results_df.iloc[0]\n",
    "print(\"=\" * 60)\n",
    "print(\"EN Ä°YÄ° PERFORMANS GÃ–STEREN MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {best_model['Model']}\")\n",
    "print(f\"DoÄŸruluk: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"Kesinlik: {best_model['Precision']:.4f}\")\n",
    "print(f\"DuyarlÄ±lÄ±k: {best_model['Recall']:.4f}\")\n",
    "print(f\"F1-Skor: {best_model['F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix Analizi\n",
    "\n",
    "En iyi performans gÃ¶steren modeller iÃ§in confusion matrix analizi yapacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi 3 modelin confusion matrix'lerini gÃ¶rselleÅŸtirme\n",
    "top_3_models = results_df.head(3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('En Ä°yi 3 Modelin Confusion Matrix Analizi', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (_, row) in enumerate(top_3_models.iterrows()):\n",
    "    model_name = row['Model']\n",
    "    predictions = models[model_name]\n",
    "    \n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Yenilebilir', 'Zehirli'],\n",
    "                yticklabels=['Yenilebilir', 'Zehirli'],\n",
    "                ax=axes[i])\n",
    "    \n",
    "    axes[i].set_title(f'{model_name}\\nAccuracy: {row[\"Accuracy\"]:.4f}', fontweight='bold')\n",
    "    axes[i].set_xlabel('Tahmin Edilen')\n",
    "    axes[i].set_ylabel('GerÃ§ek')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Ã–zellik Ã–nem Analizi\n",
    "\n",
    "Random Forest modelini kullanarak hangi Ã¶zelliklerin en Ã¶nemli olduÄŸunu analiz edeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–zellik Ã¶nem analizi\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': random_forest_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "plt.xlabel('Ã–nem Skoru')\n",
    "plt.title('Random Forest - Ã–zellik Ã–nem Analizi', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# En Ã¶nemli 10 Ã¶zelliÄŸi vurgulama\n",
    "for i in range(min(10, len(feature_importance))):\n",
    "    plt.barh(i, feature_importance.iloc[i]['importance'], color='red', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"En Ã¶nemli 10 Ã¶zellik:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Cross-Validation Analizi\n",
    "\n",
    "Modellerimizin gÃ¼venilirliÄŸini test etmek iÃ§in cross-validation analizi yapacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation analizi\n",
    "model_objects = {\n",
    "    'Logistic Regression': logistic_model,\n",
    "    'Ridge Classifier': ridge_model,\n",
    "    'Decision Tree': decision_tree_model,\n",
    "    'Naive Bayes': naive_bayes_model,\n",
    "    'Neural Network': neural_network_model,\n",
    "    'Random Forest': random_forest_model\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "for name, model in model_objects.items():\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'CV_Mean': cv_scores.mean(),\n",
    "        'CV_Std': cv_scores.std(),\n",
    "        'CV_Scores': cv_scores\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "cv_df = cv_df.sort_values('CV_Mean', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"5-FOLD CROSS-VALIDATION SONUÃ‡LARI\")\n",
    "print(\"=\" * 70)\n",
    "for _, row in cv_df.iterrows():\n",
    "    print(f\"{row['Model']:20} | Ortalama: {row['CV_Mean']:.4f} Â± {row['CV_Std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirme\n",
    "plt.figure(figsize=(12, 8))\n",
    "cv_scores_list = [row['CV_Scores'] for _, row in cv_df.iterrows()]\n",
    "model_names = cv_df['Model'].tolist()\n",
    "\n",
    "plt.boxplot(cv_scores_list, labels=model_names)\n",
    "plt.title('Cross-Validation Skor DaÄŸÄ±lÄ±mlarÄ±', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. SonuÃ§ ve DeÄŸerlendirme\n",
    "\n",
    "### Proje Ã–zeti\n",
    "\n",
    "Bu projede, mantar sÄ±nÄ±flandÄ±rmasÄ± problemi iÃ§in 6 farklÄ± makine Ã¶ÄŸrenmesi algoritmasÄ± karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Ridge Classifier** \n",
    "3. **Decision Tree**\n",
    "4. **Gaussian Naive Bayes**\n",
    "5. **Neural Network (MLP)**\n",
    "6. **Random Forest**\n",
    "\n",
    "### Ana Bulgular:\n",
    "\n",
    "- **Veri Seti**: 8124 mantar Ã¶rneÄŸi, 22 Ã¶zellik\n",
    "- **SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±**: Dengeli daÄŸÄ±lÄ±m (yaklaÅŸÄ±k %50-%50)\n",
    "- **En Ä°yi Model**: Analiz sonucunda belirlenen en yÃ¼ksek performanslÄ± model\n",
    "- **Kritik Ã–zellikler**: Ã–zellik Ã¶nem analizi ile belirlenen en etkili faktÃ¶rler\n",
    "\n",
    "### GerÃ§ek Hayat UygulamalarÄ±:\n",
    "\n",
    "1. **DoÄŸa YÃ¼rÃ¼yÃ¼ÅŸÃ¼ UygulamalarÄ±**: Mobil uygulamalarda mantar tanÄ±ma\n",
    "2. **EÄŸitim AraÃ§larÄ±**: Biyoloji eÄŸitiminde kullanÄ±m\n",
    "3. **GÃ¼venlik Sistemleri**: Yiyecek gÃ¼venliÄŸi kontrolÃ¼\n",
    "4. **AraÅŸtÄ±rma**: Mikrobiyoloji ve botanik araÅŸtÄ±rmalarÄ±\n",
    "\n",
    "### Gelecek GeliÅŸtirmeler:\n",
    "\n",
    "1. **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme**: Mantar fotoÄŸraflarÄ±ndan otomatik Ã¶zellik Ã§Ä±karÄ±mÄ±\n",
    "2. **Ensemble YÃ¶ntemler**: Birden fazla modelin kombinasyonu\n",
    "3. **Deep Learning**: CNN tabanlÄ± gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ±\n",
    "4. **Mobil Uygulama**: GerÃ§ek zamanlÄ± mantar tanÄ±ma uygulamasÄ±\n",
    "5. **Veri ArtÄ±rma**: Daha fazla mantar tÃ¼rÃ¼ ve Ã¶zellik eklenmesi\n",
    "\n",
    "### Teknik BaÅŸarÄ±lar:\n",
    "\n",
    "- YÃ¼ksek doÄŸruluk oranlarÄ± elde edildi\n",
    "- Cross-validation ile model gÃ¼venilirliÄŸi doÄŸrulandÄ±\n",
    "- Ã–zellik Ã¶nem analizi ile kritik faktÃ¶rler belirlendi\n",
    "- KapsamlÄ± model karÅŸÄ±laÅŸtÄ±rmasÄ± gerÃ§ekleÅŸtirildi\n",
    "\n",
    "Bu proje, makine Ã¶ÄŸrenmesi tekniklerinin biyolojik sÄ±nÄ±flandÄ±rma problemlerindeki etkinliÄŸini gÃ¶stermektedir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
